{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Mini.Tensor import Tensor\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "T1 = np.random.randn(4,4)\n",
    "T2 = np.random.randn(4,1)\n",
    "T3 = np.random.randn(4,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor = 1.1213652686490223>\n"
     ]
    }
   ],
   "source": [
    "true_hat = Tensor([[1], [0], [0], [0]])\n",
    "\n",
    "torch.manual_seed(100)\n",
    "t1_ = Tensor(T1)                                         \n",
    "t2_ = Tensor(T2)                                        \n",
    "t3_ = Tensor(T3)  * 0.1                                 \n",
    "\n",
    "first_ = t1_.dot(t2_)                                 \n",
    "second_ = first_ + t3_                             \n",
    "third_ =second_.Softmax(axis = 0)                               \n",
    "LOSS = -(true_hat * (third_.log())).sum() \n",
    "LOSS.backward()                               \n",
    "print(LOSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor = [[-3.06904]\n",
      " [ 0.     ]\n",
      " [ 0.     ]\n",
      " [ 0.     ]]>\n",
      "<Tensor = [[-0.67417]\n",
      " [ 0.33932]\n",
      " [ 0.10119]\n",
      " [ 0.23366]]>\n"
     ]
    }
   ],
   "source": [
    "print(third_.grad)\n",
    "print(second_.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor = [[ 0.35817 -0.69421  0.29538  0.75393]\n",
      " [-0.18027  0.34941 -0.14867 -0.37947]\n",
      " [-0.05376  0.1042  -0.04433 -0.11316]\n",
      " [-0.12414  0.2406  -0.10237 -0.2613 ]]>\n"
     ]
    }
   ],
   "source": [
    "print(t1_.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor = [[0.32583]\n",
      " [0.33932]\n",
      " [0.10119]\n",
      " [0.23366]]>\n"
     ]
    }
   ],
   "source": [
    "print(third_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                               LOG_SOFTMAX                                 #\n",
    "true_hat_1  = torch.Tensor([[1], [0], [0], [0]])\n",
    "torch.manual_seed(100)\n",
    "t1_1 = torch.tensor(T1)                                        ;t1_1.requires_grad = True \n",
    "t2_1 = torch.tensor(T2)                                        ;t2_1.requires_grad = True\n",
    "t3_1 = torch.tensor(T3)  * 0.1                                 ;t3_1.requires_grad = True\n",
    "\n",
    "\n",
    "first_1 = t1_1.matmul(t2_1)                                        ; first_1.retain_grad()\n",
    "second_1 = first_1 + t3_1                                          ; second_1.retain_grad()\n",
    "third_1 =second_1.softmax(dim = 0)                                ; third_1.retain_grad()                     \n",
    "loss_2 = -torch.sum(true_hat_1 * torch.log(third_1))\n",
    "\n",
    "loss_2.backward()                                                       ;loss_2.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0690],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000]], dtype=torch.float64)\n",
      "tensor([[-0.6742],\n",
      "        [ 0.3393],\n",
      "        [ 0.1012],\n",
      "        [ 0.2337]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(third_1.grad)\n",
    "print(second_1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor = [[-0.67417]\n",
      " [ 0.33932]\n",
      " [ 0.10119]\n",
      " [ 0.23366]]>\n"
     ]
    }
   ],
   "source": [
    "second_grad  =  Tensor(np.matmul((np.diagflat(third_.data) - np.dot(third_.data, third_.data.T)), third_.grad.data))\n",
    "print(second_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
